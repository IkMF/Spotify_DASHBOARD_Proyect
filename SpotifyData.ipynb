{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_basic_info(dataframe: pd.DataFrame) -> None:\n",
    "  \"\"\"\n",
    "  Shows basic information for the given dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pd.DataFrame\n",
    "        The dataframe to be processed\n",
    "\n",
    "  \"\"\"\n",
    "  print(f'Basic shape (rows, columns): {dataframe.shape}')\n",
    "\n",
    "  print(f'\\nColumns present in the data frame: {dataframe.columns}')\n",
    "\n",
    "  print(f'\\nIndex of the data frame: {dataframe.index}')\n",
    "\n",
    "  print('\\nGeneral dataframe information: ')\n",
    "  dataframe.info()\n",
    "\n",
    "  print('\\nFirst 10 lines of the data frame:')\n",
    "  display(dataframe.head(10))\n",
    "\n",
    "  print(f'\\nBasic statistics:')\n",
    "  display(dataframe.describe())\n",
    "  \n",
    "  \n",
    "def clean_column_names(df):\n",
    "    # Define a translation map for accented to unaccented vowels\n",
    "    accents = str.maketrans('áéíóú', 'aeiou')\n",
    "\n",
    "    # Replace accents, clean, and capitalize column names\n",
    "    df.columns = [\n",
    "        col.translate(accents).replace(\" \", \"_\").replace(\",\", \"\").capitalize()\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    # Replace accents in all string values of the DataFrame\n",
    "    df = df.applymap(lambda x: x.translate(accents) if isinstance(x, str) else x)\n",
    "\n",
    "    return df\n",
    "  \n",
    "def count_nan_per_column(df):\n",
    "    # Count NaN values per column\n",
    "    nan_count = df.isna().sum()\n",
    "    # Calculate the percentage of NaN values\n",
    "    nan_percentage = (nan_count / len(df)) * 100\n",
    "    # Combine the counts and percentages into a DataFrame\n",
    "    nan_count_df = pd.DataFrame({\n",
    "        'NaN Count': nan_count,\n",
    "        '%': nan_percentage\n",
    "    })\n",
    "    return nan_count_df\n",
    "\n",
    "def get_unique_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Returns the unique values from a specified column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - column_name (str): The name of the column for which to extract unique values.\n",
    "\n",
    "    Returns:\n",
    "    - List: A list of unique values from the specified column.\n",
    "    \"\"\"\n",
    "    # Ensure the specified column exists\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"The DataFrame must contain a '{column_name}' column.\")\n",
    "    \n",
    "    # Get unique values from the specified column\n",
    "    unique_values = df[column_name].unique().tolist()\n",
    "    \n",
    "    return unique_values\n",
    "\n",
    "def drop_nan_rows(df, column_name=None):\n",
    "    \"\"\"\n",
    "    Drops rows with NaN or equivalent missing values from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - column_name (str, optional): The column to check for NaN values. \n",
    "                                   If None, drops rows with NaN values in any column.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: A new DataFrame with rows containing NaN or equivalent missing values dropped.\n",
    "    \"\"\"\n",
    "    # Replace non-standard missing values like 'NaN', 'null', '' with np.nan\n",
    "    df = df.replace(['NaN', 'null', 'NULL', ''], np.nan)\n",
    "\n",
    "    if column_name is None:\n",
    "        # Drop rows with NaN in any column\n",
    "        return df.dropna(how='any')\n",
    "    else:\n",
    "        # Ensure the specified column exists\n",
    "        if column_name not in df.columns:\n",
    "            raise ValueError(f\"The DataFrame must contain a '{column_name}' column.\")\n",
    "        # Drop rows with NaN in the specified column\n",
    "        return df.dropna(subset=[column_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Dataset\n",
    "**Only run once a day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/asaniczka/top-spotify-songs-in-73-countries-daily-updated\n",
      "Dataset downloaded to: /Users/ikermontane/Documents/Spotify\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Authenticate with Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download the dataset\n",
    "dataset_name = \"asaniczka/top-spotify-songs-in-73-countries-daily-updated\"\n",
    "destination = \"/Users/ikermontane/Documents/Spotify\"  # Specify the destination folder\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "\n",
    "# Download and unzip the dataset\n",
    "api.dataset_download_files(dataset_name, path=destination, unzip=True)\n",
    "\n",
    "print(f\"Dataset downloaded to: {destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/ikermontane/Documents/Spotify/universal_top_spotify_songs.csv\"\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic shape (rows, columns): (1609451, 25)\n",
      "\n",
      "Columns present in the data frame: Index(['spotify_id', 'name', 'artists', 'daily_rank', 'daily_movement',\n",
      "       'weekly_movement', 'country', 'snapshot_date', 'popularity',\n",
      "       'is_explicit', 'duration_ms', 'album_name', 'album_release_date',\n",
      "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'time_signature'],\n",
      "      dtype='object')\n",
      "\n",
      "Index of the data frame: RangeIndex(start=0, stop=1609451, step=1)\n",
      "\n",
      "General dataframe information: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1609451 entries, 0 to 1609450\n",
      "Data columns (total 25 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   spotify_id          1609451 non-null  object \n",
      " 1   name                1609421 non-null  object \n",
      " 2   artists             1609422 non-null  object \n",
      " 3   daily_rank          1609451 non-null  int64  \n",
      " 4   daily_movement      1609451 non-null  int64  \n",
      " 5   weekly_movement     1609451 non-null  int64  \n",
      " 6   country             1587494 non-null  object \n",
      " 7   snapshot_date       1609451 non-null  object \n",
      " 8   popularity          1609451 non-null  int64  \n",
      " 9   is_explicit         1609451 non-null  bool   \n",
      " 10  duration_ms         1609451 non-null  int64  \n",
      " 11  album_name          1608630 non-null  object \n",
      " 12  album_release_date  1608793 non-null  object \n",
      " 13  danceability        1609451 non-null  float64\n",
      " 14  energy              1609451 non-null  float64\n",
      " 15  key                 1609451 non-null  int64  \n",
      " 16  loudness            1609451 non-null  float64\n",
      " 17  mode                1609451 non-null  int64  \n",
      " 18  speechiness         1609451 non-null  float64\n",
      " 19  acousticness        1609451 non-null  float64\n",
      " 20  instrumentalness    1609451 non-null  float64\n",
      " 21  liveness            1609451 non-null  float64\n",
      " 22  valence             1609451 non-null  float64\n",
      " 23  tempo               1609451 non-null  float64\n",
      " 24  time_signature      1609451 non-null  int64  \n",
      "dtypes: bool(1), float64(9), int64(8), object(7)\n",
      "memory usage: 296.2+ MB\n",
      "\n",
      "First 10 lines of the data frame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>daily_rank</th>\n",
       "      <th>daily_movement</th>\n",
       "      <th>weekly_movement</th>\n",
       "      <th>country</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>is_explicit</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3sK8wGT43QFpWrvNQsrQya</td>\n",
       "      <td>DtMF</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-27.405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.03200</td>\n",
       "      <td>136.020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2plbrEY59IikOBgBGLjaoe</td>\n",
       "      <td>Die With A Smile</td>\n",
       "      <td>Lady Gaga, Bruno Mars</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.777</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.53500</td>\n",
       "      <td>157.969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wJ5Qq0jBN4ajy7ouZIV1c</td>\n",
       "      <td>APT.</td>\n",
       "      <td>ROSÉ, Bruno Mars</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.93900</td>\n",
       "      <td>149.027</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2lTm559tuIvatlT1u0JYG2</td>\n",
       "      <td>BAILE INoLVIDABLE</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>-46.113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.21900</td>\n",
       "      <td>119.387</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5TFD2bmFKGhoCRbX61nXY5</td>\n",
       "      <td>NUEVAYoL</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-20.024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>137.922</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7ne4VBA60CxGM75vw0EYad</td>\n",
       "      <td>That’s So True</td>\n",
       "      <td>Gracie Abrams</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>96</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.37200</td>\n",
       "      <td>108.548</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6dOtVTDdiauQNBQEDOtlAB</td>\n",
       "      <td>BIRDS OF A FEATHER</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>97</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-10.171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.43800</td>\n",
       "      <td>104.978</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59D4DOkspUbWyMmbAPQkxZ</td>\n",
       "      <td>VOY A LLeVARTE PA PR</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-35.032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>106.295</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7d6yK8v8J484SWH5prIQiE</td>\n",
       "      <td>VeLDÁ</td>\n",
       "      <td>Bad Bunny, Omar Courtz, Dei V</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.638</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>0.03370</td>\n",
       "      <td>101.852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5WEF0icHWmAZBBMglBd599</td>\n",
       "      <td>WELTiTA</td>\n",
       "      <td>Bad Bunny, Chuwi</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-32.354</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.35700</td>\n",
       "      <td>96.140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               spotify_id                  name  \\\n",
       "0  3sK8wGT43QFpWrvNQsrQya                  DtMF   \n",
       "1  2plbrEY59IikOBgBGLjaoe      Die With A Smile   \n",
       "2  4wJ5Qq0jBN4ajy7ouZIV1c                  APT.   \n",
       "3  2lTm559tuIvatlT1u0JYG2     BAILE INoLVIDABLE   \n",
       "4  5TFD2bmFKGhoCRbX61nXY5              NUEVAYoL   \n",
       "5  7ne4VBA60CxGM75vw0EYad        That’s So True   \n",
       "6  6dOtVTDdiauQNBQEDOtlAB    BIRDS OF A FEATHER   \n",
       "7  59D4DOkspUbWyMmbAPQkxZ  VOY A LLeVARTE PA PR   \n",
       "8  7d6yK8v8J484SWH5prIQiE                 VeLDÁ   \n",
       "9  5WEF0icHWmAZBBMglBd599               WELTiTA   \n",
       "\n",
       "                         artists  daily_rank  daily_movement  weekly_movement  \\\n",
       "0                      Bad Bunny           1               0                8   \n",
       "1          Lady Gaga, Bruno Mars           2               0               -1   \n",
       "2               ROSÉ, Bruno Mars           3               0               -1   \n",
       "3                      Bad Bunny           4               0                2   \n",
       "4                      Bad Bunny           5               0                0   \n",
       "5                  Gracie Abrams           6               0               -3   \n",
       "6                  Billie Eilish           7               0               -3   \n",
       "7                      Bad Bunny           8               0               -1   \n",
       "8  Bad Bunny, Omar Courtz, Dei V           9               0               -1   \n",
       "9               Bad Bunny, Chuwi          10               0                5   \n",
       "\n",
       "  country snapshot_date  popularity  is_explicit  ...  key loudness mode  \\\n",
       "0     NaN    2025-01-15          91         True  ...    7  -27.405    0   \n",
       "1     NaN    2025-01-15         100        False  ...    6   -7.777    0   \n",
       "2     NaN    2025-01-15          90        False  ...    0   -4.477    0   \n",
       "3     NaN    2025-01-15          90         True  ...   10  -46.113    1   \n",
       "4     NaN    2025-01-15          90        False  ...    6  -20.024    1   \n",
       "5     NaN    2025-01-15          96         True  ...    1   -4.169    1   \n",
       "6     NaN    2025-01-15          97        False  ...    2  -10.171    1   \n",
       "7     NaN    2025-01-15          89         True  ...    7  -35.032    1   \n",
       "8     NaN    2025-01-15          88         True  ...    1  -18.638    1   \n",
       "9     NaN    2025-01-15          87        False  ...    4  -32.354    0   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0717        0.1770            0.2180    0.0807  0.03200  136.020   \n",
       "1       0.0304        0.3080            0.0000    0.1220  0.53500  157.969   \n",
       "2       0.2600        0.0283            0.0000    0.3550  0.93900  149.027   \n",
       "3       0.0615        0.1920            0.7900    0.1120  0.21900  119.387   \n",
       "4       0.1390        0.2650            0.9950    0.2040  0.12000  137.922   \n",
       "5       0.0368        0.2140            0.0000    0.1590  0.37200  108.548   \n",
       "6       0.0358        0.2000            0.0608    0.1170  0.43800  104.978   \n",
       "7       0.0588        0.9210            0.4530    0.4050  0.00001  106.295   \n",
       "8       0.1490        0.2900            0.0023    0.4370  0.03370  101.852   \n",
       "9       0.6000        0.8660            0.3290    0.3460  0.35700   96.140   \n",
       "\n",
       "   time_signature  \n",
       "0               4  \n",
       "1               3  \n",
       "2               4  \n",
       "3               3  \n",
       "4               4  \n",
       "5               4  \n",
       "6               4  \n",
       "7               3  \n",
       "8               3  \n",
       "9               3  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_rank</th>\n",
       "      <th>daily_movement</th>\n",
       "      <th>weekly_movement</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "      <td>1.609451e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.549174e+01</td>\n",
       "      <td>9.446476e-01</td>\n",
       "      <td>2.864874e+00</td>\n",
       "      <td>7.622463e+01</td>\n",
       "      <td>1.926886e+05</td>\n",
       "      <td>6.817503e-01</td>\n",
       "      <td>6.514109e-01</td>\n",
       "      <td>5.535638e+00</td>\n",
       "      <td>-6.497240e+00</td>\n",
       "      <td>5.391460e-01</td>\n",
       "      <td>9.461374e-02</td>\n",
       "      <td>2.733283e-01</td>\n",
       "      <td>1.793804e-02</td>\n",
       "      <td>1.703592e-01</td>\n",
       "      <td>5.524058e-01</td>\n",
       "      <td>1.222828e+02</td>\n",
       "      <td>3.903617e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.442884e+01</td>\n",
       "      <td>7.051024e+00</td>\n",
       "      <td>1.221570e+01</td>\n",
       "      <td>1.566189e+01</td>\n",
       "      <td>4.950747e+04</td>\n",
       "      <td>1.389763e-01</td>\n",
       "      <td>1.638687e-01</td>\n",
       "      <td>3.578172e+00</td>\n",
       "      <td>2.833258e+00</td>\n",
       "      <td>4.984654e-01</td>\n",
       "      <td>9.027822e-02</td>\n",
       "      <td>2.500922e-01</td>\n",
       "      <td>9.477503e-02</td>\n",
       "      <td>1.245026e-01</td>\n",
       "      <td>2.281135e-01</td>\n",
       "      <td>2.817218e+01</td>\n",
       "      <td>3.999104e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.900000e+01</td>\n",
       "      <td>-4.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.010000e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.434100e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.450000e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.390000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>1.608120e+05</td>\n",
       "      <td>5.890000e-01</td>\n",
       "      <td>5.520000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-7.787000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.880000e-02</td>\n",
       "      <td>6.670000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.590000e-02</td>\n",
       "      <td>3.720000e-01</td>\n",
       "      <td>1.000120e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.852380e+05</td>\n",
       "      <td>7.020000e-01</td>\n",
       "      <td>6.700000e-01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-5.992000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.780000e-02</td>\n",
       "      <td>1.870000e-01</td>\n",
       "      <td>1.220000e-06</td>\n",
       "      <td>1.210000e-01</td>\n",
       "      <td>5.540000e-01</td>\n",
       "      <td>1.199600e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>2.174900e+05</td>\n",
       "      <td>7.850000e-01</td>\n",
       "      <td>7.650000e-01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>-4.693000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.100000e-01</td>\n",
       "      <td>4.360000e-01</td>\n",
       "      <td>7.650000e-05</td>\n",
       "      <td>2.050000e-01</td>\n",
       "      <td>7.370000e-01</td>\n",
       "      <td>1.401080e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>9.396660e+05</td>\n",
       "      <td>9.880000e-01</td>\n",
       "      <td>9.980000e-01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.233000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.370000e-01</td>\n",
       "      <td>9.960000e-01</td>\n",
       "      <td>9.950000e-01</td>\n",
       "      <td>9.780000e-01</td>\n",
       "      <td>9.920000e-01</td>\n",
       "      <td>2.360890e+02</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         daily_rank  daily_movement  weekly_movement    popularity  \\\n",
       "count  1.609451e+06    1.609451e+06     1.609451e+06  1.609451e+06   \n",
       "mean   2.549174e+01    9.446476e-01     2.864874e+00  7.622463e+01   \n",
       "std    1.442884e+01    7.051024e+00     1.221570e+01  1.566189e+01   \n",
       "min    1.000000e+00   -4.900000e+01    -4.900000e+01  0.000000e+00   \n",
       "25%    1.300000e+01   -1.000000e+00    -3.000000e+00  6.500000e+01   \n",
       "50%    2.500000e+01    0.000000e+00     0.000000e+00  8.000000e+01   \n",
       "75%    3.800000e+01    2.000000e+00     5.000000e+00  8.800000e+01   \n",
       "max    5.000000e+01    4.900000e+01     4.900000e+01  1.000000e+02   \n",
       "\n",
       "        duration_ms  danceability        energy           key      loudness  \\\n",
       "count  1.609451e+06  1.609451e+06  1.609451e+06  1.609451e+06  1.609451e+06   \n",
       "mean   1.926886e+05  6.817503e-01  6.514109e-01  5.535638e+00 -6.497240e+00   \n",
       "std    4.950747e+04  1.389763e-01  1.638687e-01  3.578172e+00  2.833258e+00   \n",
       "min    0.000000e+00  0.000000e+00  2.010000e-05  0.000000e+00 -5.434100e+01   \n",
       "25%    1.608120e+05  5.890000e-01  5.520000e-01  2.000000e+00 -7.787000e+00   \n",
       "50%    1.852380e+05  7.020000e-01  6.700000e-01  6.000000e+00 -5.992000e+00   \n",
       "75%    2.174900e+05  7.850000e-01  7.650000e-01  9.000000e+00 -4.693000e+00   \n",
       "max    9.396660e+05  9.880000e-01  9.980000e-01  1.100000e+01  3.233000e+00   \n",
       "\n",
       "               mode   speechiness  acousticness  instrumentalness  \\\n",
       "count  1.609451e+06  1.609451e+06  1.609451e+06      1.609451e+06   \n",
       "mean   5.391460e-01  9.461374e-02  2.733283e-01      1.793804e-02   \n",
       "std    4.984654e-01  9.027822e-02  2.500922e-01      9.477503e-02   \n",
       "min    0.000000e+00  0.000000e+00  3.450000e-06      0.000000e+00   \n",
       "25%    0.000000e+00  3.880000e-02  6.670000e-02      0.000000e+00   \n",
       "50%    1.000000e+00  5.780000e-02  1.870000e-01      1.220000e-06   \n",
       "75%    1.000000e+00  1.100000e-01  4.360000e-01      7.650000e-05   \n",
       "max    1.000000e+00  9.370000e-01  9.960000e-01      9.950000e-01   \n",
       "\n",
       "           liveness       valence         tempo  time_signature  \n",
       "count  1.609451e+06  1.609451e+06  1.609451e+06    1.609451e+06  \n",
       "mean   1.703592e-01  5.524058e-01  1.222828e+02    3.903617e+00  \n",
       "std    1.245026e-01  2.281135e-01  2.817218e+01    3.999104e-01  \n",
       "min    1.390000e-02  0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "25%    9.590000e-02  3.720000e-01  1.000120e+02    4.000000e+00  \n",
       "50%    1.210000e-01  5.540000e-01  1.199600e+02    4.000000e+00  \n",
       "75%    2.050000e-01  7.370000e-01  1.401080e+02    4.000000e+00  \n",
       "max    9.780000e-01  9.920000e-01  2.360890e+02    5.000000e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_basic_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/0wvkmnks13b_gbyk2zfz4kt40000gn/T/ipykernel_75550/2525275159.py:38: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.translate(accents) if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "df1 = clean_column_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Spotify_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>30</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artists</th>\n",
       "      <td>29</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily_rank</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily_movement</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekly_movement</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>21957</td>\n",
       "      <td>1.364254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snapshot_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is_explicit</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration_ms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Album_name</th>\n",
       "      <td>821</td>\n",
       "      <td>0.051011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Album_release_date</th>\n",
       "      <td>658</td>\n",
       "      <td>0.040884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Danceability</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loudness</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speechiness</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acousticness</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrumentalness</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liveness</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valence</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tempo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_signature</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NaN Count         %\n",
       "Spotify_id                  0  0.000000\n",
       "Name                       30  0.001864\n",
       "Artists                    29  0.001802\n",
       "Daily_rank                  0  0.000000\n",
       "Daily_movement              0  0.000000\n",
       "Weekly_movement             0  0.000000\n",
       "Country                 21957  1.364254\n",
       "Snapshot_date               0  0.000000\n",
       "Popularity                  0  0.000000\n",
       "Is_explicit                 0  0.000000\n",
       "Duration_ms                 0  0.000000\n",
       "Album_name                821  0.051011\n",
       "Album_release_date        658  0.040884\n",
       "Danceability                0  0.000000\n",
       "Energy                      0  0.000000\n",
       "Key                         0  0.000000\n",
       "Loudness                    0  0.000000\n",
       "Mode                        0  0.000000\n",
       "Speechiness                 0  0.000000\n",
       "Acousticness                0  0.000000\n",
       "Instrumentalness            0  0.000000\n",
       "Liveness                    0  0.000000\n",
       "Valence                     0  0.000000\n",
       "Tempo                       0  0.000000\n",
       "Time_signature              0  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nan_per_column(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spotify_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artists</th>\n",
       "      <th>Daily_rank</th>\n",
       "      <th>Daily_movement</th>\n",
       "      <th>Weekly_movement</th>\n",
       "      <th>Country</th>\n",
       "      <th>Snapshot_date</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Is_explicit</th>\n",
       "      <th>...</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3sK8wGT43QFpWrvNQsrQya</td>\n",
       "      <td>DtMF</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-27.405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.032</td>\n",
       "      <td>136.020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2plbrEY59IikOBgBGLjaoe</td>\n",
       "      <td>Die With A Smile</td>\n",
       "      <td>Lady Gaga, Bruno Mars</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.777</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.535</td>\n",
       "      <td>157.969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wJ5Qq0jBN4ajy7ouZIV1c</td>\n",
       "      <td>APT.</td>\n",
       "      <td>ROSÉ, Bruno Mars</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.939</td>\n",
       "      <td>149.027</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2lTm559tuIvatlT1u0JYG2</td>\n",
       "      <td>BAILE INoLVIDABLE</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>-46.113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.219</td>\n",
       "      <td>119.387</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5TFD2bmFKGhoCRbX61nXY5</td>\n",
       "      <td>NUEVAYoL</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-20.024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.120</td>\n",
       "      <td>137.922</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609446</th>\n",
       "      <td>0AYt6NMyyLd0rLuvr0UkMH</td>\n",
       "      <td>Slime You Out (feat. SZA)</td>\n",
       "      <td>Drake, SZA</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>AE</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>84</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.105</td>\n",
       "      <td>88.880</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609447</th>\n",
       "      <td>2Gk6fi0dqt91NKvlzGsmm7</td>\n",
       "      <td>SAY MY GRACE (feat. Travis Scott)</td>\n",
       "      <td>Offset, Travis Scott</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>AE</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.476</td>\n",
       "      <td>121.879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609448</th>\n",
       "      <td>26b3oVLrRUaaybJulow9kz</td>\n",
       "      <td>People</td>\n",
       "      <td>Libianca</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>AE</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.5510</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.693</td>\n",
       "      <td>124.357</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609449</th>\n",
       "      <td>5ydjxBSUIDn26MFzU3asP4</td>\n",
       "      <td>Rainy Days</td>\n",
       "      <td>V</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AE</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>-8.016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.282</td>\n",
       "      <td>74.828</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609450</th>\n",
       "      <td>59NraMJsLaMCVtwXTSia8i</td>\n",
       "      <td>Prada</td>\n",
       "      <td>cassö, RAYE, D-Block Europe</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AE</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>94</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.422</td>\n",
       "      <td>141.904</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609451 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Spotify_id                               Name  \\\n",
       "0        3sK8wGT43QFpWrvNQsrQya                               DtMF   \n",
       "1        2plbrEY59IikOBgBGLjaoe                   Die With A Smile   \n",
       "2        4wJ5Qq0jBN4ajy7ouZIV1c                               APT.   \n",
       "3        2lTm559tuIvatlT1u0JYG2                  BAILE INoLVIDABLE   \n",
       "4        5TFD2bmFKGhoCRbX61nXY5                           NUEVAYoL   \n",
       "...                         ...                                ...   \n",
       "1609446  0AYt6NMyyLd0rLuvr0UkMH          Slime You Out (feat. SZA)   \n",
       "1609447  2Gk6fi0dqt91NKvlzGsmm7  SAY MY GRACE (feat. Travis Scott)   \n",
       "1609448  26b3oVLrRUaaybJulow9kz                             People   \n",
       "1609449  5ydjxBSUIDn26MFzU3asP4                         Rainy Days   \n",
       "1609450  59NraMJsLaMCVtwXTSia8i                              Prada   \n",
       "\n",
       "                             Artists  Daily_rank  Daily_movement  \\\n",
       "0                          Bad Bunny           1               0   \n",
       "1              Lady Gaga, Bruno Mars           2               0   \n",
       "2                   ROSÉ, Bruno Mars           3               0   \n",
       "3                          Bad Bunny           4               0   \n",
       "4                          Bad Bunny           5               0   \n",
       "...                              ...         ...             ...   \n",
       "1609446                   Drake, SZA          46               4   \n",
       "1609447         Offset, Travis Scott          47               3   \n",
       "1609448                     Libianca          48               2   \n",
       "1609449                            V          49               1   \n",
       "1609450  cassö, RAYE, D-Block Europe          50               0   \n",
       "\n",
       "         Weekly_movement Country Snapshot_date  Popularity  Is_explicit  ...  \\\n",
       "0                      8     NaN    2025-01-15          91         True  ...   \n",
       "1                     -1     NaN    2025-01-15         100        False  ...   \n",
       "2                     -1     NaN    2025-01-15          90        False  ...   \n",
       "3                      2     NaN    2025-01-15          90         True  ...   \n",
       "4                      0     NaN    2025-01-15          90        False  ...   \n",
       "...                  ...     ...           ...         ...          ...  ...   \n",
       "1609446                0      AE    2023-10-18          84         True  ...   \n",
       "1609447                0      AE    2023-10-18          80         True  ...   \n",
       "1609448                0      AE    2023-10-18          88        False  ...   \n",
       "1609449                0      AE    2023-10-18          88        False  ...   \n",
       "1609450                0      AE    2023-10-18          94         True  ...   \n",
       "\n",
       "         Key Loudness Mode  Speechiness  Acousticness  Instrumentalness  \\\n",
       "0          7  -27.405    0       0.0717        0.1770          0.218000   \n",
       "1          6   -7.777    0       0.0304        0.3080          0.000000   \n",
       "2          0   -4.477    0       0.2600        0.0283          0.000000   \n",
       "3         10  -46.113    1       0.0615        0.1920          0.790000   \n",
       "4          6  -20.024    1       0.1390        0.2650          0.995000   \n",
       "...      ...      ...  ...          ...           ...               ...   \n",
       "1609446    5   -9.243    0       0.0502        0.5080          0.000000   \n",
       "1609447   10   -5.060    1       0.0452        0.0585          0.000000   \n",
       "1609448   10   -7.621    0       0.0678        0.5510          0.000013   \n",
       "1609449    9   -8.016    0       0.0875        0.7390          0.000000   \n",
       "1609450    8   -5.804    1       0.0375        0.0010          0.000002   \n",
       "\n",
       "         Liveness  Valence    Tempo  Time_signature  \n",
       "0          0.0807    0.032  136.020               4  \n",
       "1          0.1220    0.535  157.969               3  \n",
       "2          0.3550    0.939  149.027               4  \n",
       "3          0.1120    0.219  119.387               3  \n",
       "4          0.2040    0.120  137.922               4  \n",
       "...           ...      ...      ...             ...  \n",
       "1609446    0.2590    0.105   88.880               3  \n",
       "1609447    0.1320    0.476  121.879               4  \n",
       "1609448    0.1020    0.693  124.357               5  \n",
       "1609449    0.1480    0.282   74.828               4  \n",
       "1609450    0.1130    0.422  141.904               4  \n",
       "\n",
       "[1609451 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_glb(df):\n",
    "    \"\"\"\n",
    "    Replaces all NaN values in the 'Country' column with 'GLB'.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame containing a 'Country' column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The updated DataFrame with NaN replaced by 'GLB' in the 'Country' column.\n",
    "    \"\"\"\n",
    "    # Ensure the 'Country' column exists\n",
    "    if 'Country' not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'Country' column.\")\n",
    "    \n",
    "    # Replace all NaN with 'GLB' in the 'Country' column\n",
    "    df['Country'] = df['Country'].fillna('GLB')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = replace_nan_with_glb(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_and_store_duplicates(df):\n",
    "    \"\"\"\n",
    "    Identifies and removes exact row duplicates in all columns of a DataFrame.\n",
    "    \n",
    "    Prints the count of duplicates and a message after removal. \n",
    "    Creates a DataFrame called `df_duplicates` containing the duplicates for later reference.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The updated DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    global df_duplicates\n",
    "\n",
    "    # Identify duplicate rows\n",
    "    df_duplicates = df[df.duplicated(keep=False)]\n",
    "    \n",
    "    # Count the number of duplicate rows\n",
    "    duplicate_count = df_duplicates.shape[0]\n",
    "    \n",
    "    # Remove duplicates from the DataFrame\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    \n",
    "    # Print results\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"{duplicate_count} duplicates found and removed.\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "    print(\"All duplicates successfully deleted.\")\n",
    "    print(\"Duplicates can be accessed through df_duplicates\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n",
      "All duplicates successfully deleted.\n",
      "Duplicates can be accessed through df_duplicates\n"
     ]
    }
   ],
   "source": [
    "df1 = remove_and_store_duplicates(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_country_data(df):\n",
    "    \"\"\"\n",
    "    Updates the DataFrame by renaming the 'Country' column to 'Country_code', \n",
    "    and adding two new columns: 'Country_name' and 'Region', based on the Country_code.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame with a 'Country' column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The updated DataFrame with new columns and renamed 'Country' column.\n",
    "    \"\"\"\n",
    "    # Mapping of country codes to names and regions\n",
    "    country_data = {\n",
    "        'ZA': ('South Africa', 'Africa'),\n",
    "        'VN': ('Vietnam', 'Asia'),\n",
    "        'VE': ('Venezuela', 'America'),\n",
    "        'UY': ('Uruguay', 'America'),\n",
    "        'US': ('United States of America', 'America'),\n",
    "        'UA': ('Ukraine', 'Europe'),\n",
    "        'TW': ('Taiwan', 'Asia'),\n",
    "        'TR': ('Turkey', 'Asia'),\n",
    "        'TH': ('Thailand', 'Asia'),\n",
    "        'SV': ('El Salvador', 'America'),\n",
    "        'SK': ('Slovakia', 'Europe'),\n",
    "        'SG': ('Singapore', 'Asia'),\n",
    "        'SE': ('Sweden', 'Europe'),\n",
    "        'SA': ('Saudi Arabia', 'Asia'),\n",
    "        'RO': ('Romania', 'Europe'),\n",
    "        'PY': ('Paraguay', 'America'),\n",
    "        'PT': ('Portugal', 'Europe'),\n",
    "        'PL': ('Poland', 'Europe'),\n",
    "        'PK': ('Pakistan', 'Asia'),\n",
    "        'PH': ('Philippines', 'Asia'),\n",
    "        'PE': ('Peru', 'America'),\n",
    "        'PA': ('Panama', 'America'),\n",
    "        'NZ': ('New Zealand', 'Oceania'),\n",
    "        'NO': ('Norway', 'Europe'),\n",
    "        'NL': ('Netherlands', 'Europe'),\n",
    "        'NI': ('Nicaragua', 'America'),\n",
    "        'NG': ('Nigeria', 'Africa'),\n",
    "        'MY': ('Malaysia', 'Asia'),\n",
    "        'MX': ('Mexico', 'America'),\n",
    "        'MA': ('Morocco', 'Africa'),\n",
    "        'LV': ('Latvia', 'Europe'),\n",
    "        'LU': ('Luxembourg', 'Europe'),\n",
    "        'LT': ('Lithuania', 'Europe'),\n",
    "        'KZ': ('Kazakhstan', 'Asia'),\n",
    "        'KR': ('South Korea', 'Asia'),\n",
    "        'JP': ('Japan', 'Asia'),\n",
    "        'IT': ('Italy', 'Europe'),\n",
    "        'IS': ('Iceland', 'Europe'),\n",
    "        'IN': ('India', 'Asia'),\n",
    "        'IL': ('Israel', 'Asia'),\n",
    "        'IE': ('Ireland', 'Europe'),\n",
    "        'ID': ('Indonesia', 'Asia'),\n",
    "        'HU': ('Hungary', 'Europe'),\n",
    "        'HN': ('Honduras', 'America'),\n",
    "        'HK': ('Hong Kong', 'Asia'),\n",
    "        'GT': ('Guatemala', 'America'),\n",
    "        'GR': ('Greece', 'Europe'),\n",
    "        'FR': ('France', 'Europe'),\n",
    "        'FI': ('Finland', 'Europe'),\n",
    "        'ES': ('Spain', 'Europe'),\n",
    "        'EG': ('Egypt', 'Africa'),\n",
    "        'EE': ('Estonia', 'Europe'),\n",
    "        'EC': ('Ecuador', 'America'),\n",
    "        'DO': ('Dominican Republic', 'America'),\n",
    "        'DK': ('Denmark', 'Europe'),\n",
    "        'DE': ('Germany', 'Europe'),\n",
    "        'CZ': ('Czech Republic', 'Europe'),\n",
    "        'CR': ('Costa Rica', 'America'),\n",
    "        'CO': ('Colombia', 'America'),\n",
    "        'CL': ('Chile', 'America'),\n",
    "        'CH': ('Switzerland', 'Europe'),\n",
    "        'CA': ('Canada', 'America'),\n",
    "        'BY': ('Belarus', 'Europe'),\n",
    "        'BR': ('Brazil', 'America'),\n",
    "        'BO': ('Bolivia', 'America'),\n",
    "        'BG': ('Bulgaria', 'Europe'),\n",
    "        'BE': ('Belgium', 'Europe'),\n",
    "        'AU': ('Australia', 'Oceania'),\n",
    "        'AT': ('Austria', 'Europe'),\n",
    "        'AR': ('Argentina', 'America'),\n",
    "        'AE': ('United Arab Emirates', 'Asia'),\n",
    "        'GB': ('United Kingdom', 'Europe'),\n",
    "        'GLB': ('Global', 'Global')\n",
    "    }\n",
    "\n",
    "    # Rename the column 'Country' to 'Country_code'\n",
    "    df = df.rename(columns={'Country': 'Country_code'})\n",
    "\n",
    "    # Add a new column 'Country_name' using the mapping\n",
    "    df['Country_name'] = df['Country_code'].map(lambda code: country_data.get(code, ('Unknown', 'Unknown'))[0])\n",
    "\n",
    "    # Add a new column 'Region' using the mapping\n",
    "    df['Region'] = df['Country_code'].map(lambda code: country_data.get(code, ('Unknown', 'Unknown'))[1])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = enrich_country_data(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_df_to_csv(df, filename=\"spot_dash.csv\"):\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame to a CSV file in the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to save.\n",
    "    - filename (str): The name of the CSV file (default is 'data.csv').\n",
    "    \"\"\"\n",
    "    # Define the target path\n",
    "    path = \"/Users/ikermontane/Documents/Spotify\"\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"The directory '{path}' does not exist.\")\n",
    "    \n",
    "    # Define the full file path\n",
    "    file_path = os.path.join(path, filename)\n",
    "    \n",
    "    # Save the DataFrame to the CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"DataFrame saved successfully to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved successfully to: /Users/ikermontane/Documents/Spotify/spot_dash.csv\n"
     ]
    }
   ],
   "source": [
    "download_df_to_csv(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed weekly data saved to: /Users/ikermontane/Documents/Spotify/precomputed_weekly_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>week</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>0.534660</td>\n",
       "      <td>0.683980</td>\n",
       "      <td>0.652640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>0.543814</td>\n",
       "      <td>0.690457</td>\n",
       "      <td>0.661586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>0.516443</td>\n",
       "      <td>0.674186</td>\n",
       "      <td>0.647229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>2024-02-05</td>\n",
       "      <td>0.484114</td>\n",
       "      <td>0.657871</td>\n",
       "      <td>0.632414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global</td>\n",
       "      <td>2024-02-12</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.637314</td>\n",
       "      <td>0.659829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17273</th>\n",
       "      <td>Oceania, Europe, America, Asia, Africa</td>\n",
       "      <td>2024-12-16</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.645106</td>\n",
       "      <td>0.625787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17274</th>\n",
       "      <td>Oceania, Europe, America, Asia, Africa</td>\n",
       "      <td>2024-12-23</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.641062</td>\n",
       "      <td>0.623877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17275</th>\n",
       "      <td>Oceania, Europe, America, Asia, Africa</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.674925</td>\n",
       "      <td>0.652796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17276</th>\n",
       "      <td>Oceania, Europe, America, Asia, Africa</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0.483506</td>\n",
       "      <td>0.608132</td>\n",
       "      <td>0.594295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17277</th>\n",
       "      <td>Oceania, Europe, America, Asia, Africa</td>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>0.460796</td>\n",
       "      <td>0.598477</td>\n",
       "      <td>0.576527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17278 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Region       week   Valence  \\\n",
       "0                                      Global 2024-01-15  0.534660   \n",
       "1                                      Global 2024-01-22  0.543814   \n",
       "2                                      Global 2024-01-29  0.516443   \n",
       "3                                      Global 2024-02-05  0.484114   \n",
       "4                                      Global 2024-02-12  0.461700   \n",
       "...                                       ...        ...       ...   \n",
       "17273  Oceania, Europe, America, Asia, Africa 2024-12-16  0.574074   \n",
       "17274  Oceania, Europe, America, Asia, Africa 2024-12-23  0.587362   \n",
       "17275  Oceania, Europe, America, Asia, Africa 2024-12-30  0.564583   \n",
       "17276  Oceania, Europe, America, Asia, Africa 2025-01-06  0.483506   \n",
       "17277  Oceania, Europe, America, Asia, Africa 2025-01-13  0.460796   \n",
       "\n",
       "       Danceability    Energy  \n",
       "0          0.683980  0.652640  \n",
       "1          0.690457  0.661586  \n",
       "2          0.674186  0.647229  \n",
       "3          0.657871  0.632414  \n",
       "4          0.637314  0.659829  \n",
       "...             ...       ...  \n",
       "17273      0.645106  0.625787  \n",
       "17274      0.641062  0.623877  \n",
       "17275      0.674925  0.652796  \n",
       "17276      0.608132  0.594295  \n",
       "17277      0.598477  0.576527  \n",
       "\n",
       "[17278 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import permutations\n",
    "\n",
    "def get_effective_date():\n",
    "    \"\"\"\n",
    "    Determines the effective date based on Mexico City time.\n",
    "    If the current time is before 5:30 PM, it uses yesterday's date.\n",
    "    \"\"\"\n",
    "    # Define the Mexico City timezone\n",
    "    mexico_city_tz = pytz.timezone(\"America/Mexico_City\")\n",
    "\n",
    "    # Get the current time in the Mexico City timezone\n",
    "    now = datetime.now(mexico_city_tz)\n",
    "\n",
    "    # Determine the effective date\n",
    "    if now.hour < 17 or (now.hour == 17 and now.minute < 30):\n",
    "        # Before 5:30 PM, use the previous day's date\n",
    "        effective_date = now - timedelta(days=1)\n",
    "    else:\n",
    "        # After 5:30 PM, use today's date\n",
    "        effective_date = now\n",
    "\n",
    "    # Return the date in 'YYYY-MM-DD' format\n",
    "    return effective_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def precompute_weekly_averages_by_region_permutations(df2):\n",
    "    \"\"\"\n",
    "    Precomputes weekly averages for the past 365 days grouped by all region permutations.\n",
    "    Saves the precomputed data into a CSV file for each permutation.\n",
    "    \"\"\"\n",
    "    # Get the effective date based on Mexico City time\n",
    "    effective_date = datetime.strptime(get_effective_date(), '%Y-%m-%d')\n",
    "\n",
    "    # Get the past 365 dates\n",
    "    past_365_dates = [(effective_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(365)]\n",
    "\n",
    "    # Filter data for the past 365 days\n",
    "    filtered_df = df2[df2['Snapshot_date'].isin(past_365_dates)].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Ensure the Snapshot_date column is in datetime format\n",
    "    filtered_df['Snapshot_date'] = pd.to_datetime(filtered_df['Snapshot_date'])\n",
    "\n",
    "    # Add a \"week\" column for grouping\n",
    "    filtered_df['week'] = filtered_df['Snapshot_date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "\n",
    "    # Filter rows where Daily_rank <= 10\n",
    "    filtered_df = filtered_df[filtered_df['Daily_rank'] <= 10]\n",
    "\n",
    "    # If the filtered DataFrame is empty, return an empty DataFrame\n",
    "    if filtered_df.empty:\n",
    "        print(\"No data found for the specified date range and criteria.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get unique regions (excluding Global)\n",
    "    regions = filtered_df['Region'].dropna().unique().tolist()\n",
    "    if 'Global' in regions:\n",
    "        regions.remove('Global')\n",
    "\n",
    "    # Calculate for Global separately\n",
    "    global_data = (\n",
    "        filtered_df[filtered_df['Region'] == 'Global']\n",
    "        .groupby(['Region', 'week'])\n",
    "        .agg({\n",
    "            'Valence': 'mean',\n",
    "            'Danceability': 'mean',\n",
    "            'Energy': 'mean'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Initialize a list to store all permutations' results\n",
    "    all_permutations_data = [global_data]\n",
    "\n",
    "    # Iterate over all permutations of regions (1 to N regions)\n",
    "    for r in range(1, len(regions) + 1):\n",
    "        for permutation in permutations(regions, r):\n",
    "            # Filter data for the permutation of regions\n",
    "            perm_df = filtered_df[filtered_df['Region'].isin(permutation)]\n",
    "\n",
    "            # Calculate weekly averages for the permutation\n",
    "            perm_data = (\n",
    "                perm_df\n",
    "                .groupby(['week'])\n",
    "                .agg({\n",
    "                    'Valence': 'mean',\n",
    "                    'Danceability': 'mean',\n",
    "                    'Energy': 'mean'\n",
    "                })\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            # Add a \"Region\" column representing the permutation\n",
    "            perm_data['Region'] = ', '.join(permutation)\n",
    "\n",
    "            # Append the result to the list\n",
    "            all_permutations_data.append(perm_data)\n",
    "\n",
    "    # Combine all results into a single DataFrame\n",
    "    final_data = pd.concat(all_permutations_data, ignore_index=True)\n",
    "\n",
    "    # Save the precomputed data into a CSV file\n",
    "    file_path = \"/Users/ikermontane/Documents/Spotify/precomputed_weekly_data.csv\"\n",
    "    final_data.to_csv(file_path, index=False)\n",
    "    print(f\"Precomputed weekly data saved to: {file_path}\")\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "# Call the function and display the result\n",
    "weekly_data = precompute_weekly_averages_by_region_permutations(df2)\n",
    "display(weekly_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
